{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:21.555017Z",
     "iopub.status.busy": "2022-11-16T13:56:21.554694Z",
     "iopub.status.idle": "2022-11-16T13:56:22.569364Z",
     "shell.execute_reply": "2022-11-16T13:56:22.568464Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch.nn import BatchNorm1d\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:22.572579Z",
     "iopub.status.busy": "2022-11-16T13:56:22.572163Z",
     "iopub.status.idle": "2022-11-16T13:56:22.675307Z",
     "shell.execute_reply": "2022-11-16T13:56:22.674711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "args = paser.parse_args(\"\")\n",
    "args.seed = 2023\n",
    "    \n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:22.711927Z",
     "iopub.status.busy": "2022-11-16T13:56:22.711231Z",
     "iopub.status.idle": "2022-11-16T13:56:22.719077Z",
     "shell.execute_reply": "2022-11-16T13:56:22.718483Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def atom_features(atom):\n",
    "    results = np.array(one_of_k_encoding_unk(atom.GetSymbol(), ['B', 'C', 'Cl', 'N', 'O', 'P', 'S']) + \n",
    "                       one_of_k_encoding_unk(atom.GetDegree(), [1, 2, 3, 4]) + \n",
    "                       one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3]) + \n",
    "                       [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \n",
    "                       one_of_k_encoding_unk(atom.GetHybridization(), [Chem.rdchem.HybridizationType.SP, \n",
    "                                                                       Chem.rdchem.HybridizationType.SP2, \n",
    "                                                                       Chem.rdchem.HybridizationType.SP3, \n",
    "                                                                       Chem.rdchem.HybridizationType.SP3D, \n",
    "                                                                       Chem.rdchem.HybridizationType.SP3D2]) + \n",
    "                       [atom.GetIsAromatic()]+\n",
    "                       one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3]))\n",
    "    return results\n",
    " \n",
    "\n",
    "def get_bond_pair(mol):\n",
    "    bonds = mol.GetBonds()\n",
    "    res = [[],[]]\n",
    "    for bond in bonds:\n",
    "        res[0] += [bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]\n",
    "        res[1] += [bond.GetEndAtomIdx(), bond.GetBeginAtomIdx()]\n",
    "    return res\n",
    " \n",
    "def mol2vec(mol):\n",
    "    atoms = mol.GetAtoms()\n",
    "    node_feat= [atom_features(atom) for atom in atoms]\n",
    "    edge_index = get_bond_pair(mol)\n",
    "    data = Data(x=torch.tensor(node_feat, dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:22.721342Z",
     "iopub.status.busy": "2022-11-16T13:56:22.721156Z",
     "iopub.status.idle": "2022-11-16T13:56:22.724772Z",
     "shell.execute_reply": "2022-11-16T13:56:22.724163Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_mol(df, col, y='Class'):\n",
    "    mols = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        mols[Chem.MolFromSmiles(df[col].iloc[i])] = df[y].iloc[i]\n",
    "    return mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:22.727047Z",
     "iopub.status.busy": "2022-11-16T13:56:22.726655Z",
     "iopub.status.idle": "2022-11-16T13:56:22.730052Z",
     "shell.execute_reply": "2022-11-16T13:56:22.729488Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_vec(mols):\n",
    "    X = [mol2vec(m) for m in mols.keys()]\n",
    "    for i, data in enumerate(X):\n",
    "        y = list(mols.values())[i]\n",
    "        data.y = torch.tensor([y], dtype=torch.long)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head(smi):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        for n in range(mol.GetNumAtoms()):\n",
    "            frag_list = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                idx = atom.GetIdx()\n",
    "                degree = atom.GetDegree()\n",
    "                if degree == 1:\n",
    "#                     if atom.GetSymbol() == 'N' and str(atom.GetHybridization()) == 'SP3':\n",
    "                    if atom.GetSymbol() != 'C':\n",
    "                        frag_list.append(idx)\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    frag_list.append(idx)\n",
    "            frag = Chem.MolFragmentToSmiles(mol, atomsToUse=frag_list)\n",
    "            mol = Chem.MolFromSmiles(frag)\n",
    "        return Chem.MolToSmiles(mol)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Category</th>\n",
       "      <th>SP3_N</th>\n",
       "      <th>Head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=CCCCCC(C)CCCCCC#CCCC(OC)C(=O)OC(=O)C(CCC#CCC...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(CO)OC(=O)CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCCCCC[C@H](O)CC(=O)N[C@@H](CO)C(=O)O</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(CCO)N[C@@H](CO)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCCCC)CC(=O)N[...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>1</td>\n",
       "      <td>NCCC[C@H](NC(=O)CCOC=O)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC/C=C\\C/C=C\\C/C=C\\CCCCCCCC(=O)N[C@@H](CCC(N)=...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>NC(=O)CC[C@H](NC=O)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)CCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCC(C)C)CC(...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=COCCC(=O)N[C@@H](CO)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47065</th>\n",
       "      <td>CCCCCCCCCCC[C@H](CC1=CC(=O)C=C(OC)C1=O)OC(C)=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=COCCC1=CC(=O)C=C(O)C1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47066</th>\n",
       "      <td>CCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47067</th>\n",
       "      <td>CCCCCCCCCCCC1=C(O)C(=O)C=C(OC)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47068</th>\n",
       "      <td>CCCCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47069</th>\n",
       "      <td>CCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47070 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SMILES     Category  SP3_N  \\\n",
       "0      C=CCCCCC(C)CCCCCC#CCCC(OC)C(=O)OC(=O)C(CCC#CCC...  Fatty Acyls      0   \n",
       "1                 CCCCCCC[C@H](O)CC(=O)N[C@@H](CO)C(=O)O  Fatty Acyls      0   \n",
       "2      CCCCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCCCC)CC(=O)N[...  Fatty Acyls      1   \n",
       "3      CC/C=C\\C/C=C\\C/C=C\\CCCCCCCC(=O)N[C@@H](CCC(N)=...  Fatty Acyls      0   \n",
       "4      CC(C)CCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCC(C)C)CC(...  Fatty Acyls      0   \n",
       "...                                                  ...          ...    ...   \n",
       "47065     CCCCCCCCCCC[C@H](CC1=CC(=O)C=C(OC)C1=O)OC(C)=O  Polyketides      0   \n",
       "47066                  CCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "47067                 CCCCCCCCCCCC1=C(O)C(=O)C=C(OC)C1=O  Polyketides      0   \n",
       "47068              CCCCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "47069                CCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "\n",
       "                                Head  \n",
       "0                    O=C(CO)OC(=O)CO  \n",
       "1          O=C(CCO)N[C@@H](CO)C(=O)O  \n",
       "2      NCCC[C@H](NC(=O)CCOC=O)C(=O)O  \n",
       "3          NC(=O)CC[C@H](NC=O)C(=O)O  \n",
       "4       O=COCCC(=O)N[C@@H](CO)C(=O)O  \n",
       "...                              ...  \n",
       "47065      O=COCCC1=CC(=O)C=C(O)C1=O  \n",
       "47066           O=C1C=C(O)C(=O)C=C1O  \n",
       "47067           O=C1C=C(O)C(=O)C=C1O  \n",
       "47068           O=C1C=C(O)C(=O)C=C1O  \n",
       "47069           O=C1C=C(O)C(=O)C=C1O  \n",
       "\n",
       "[47070 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./LMSD_Head_dataset.csv')\n",
    "# df = df[df['SP3_N'] != 0].reset_index(drop=True)\n",
    "df = df[df['Head'] != 0].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category            \n",
       "Fatty Acyls             10335\n",
       "Glycerophospholipids    10018\n",
       "Glycerolipids            7739\n",
       "Polyketides              7145\n",
       "Sphingolipids            4533\n",
       "Sterol Lipids            3625\n",
       "Prenol Lipids            2330\n",
       "Saccharolipids           1345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2d1b86c73b4a389d2479e551ed52d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Category</th>\n",
       "      <th>SP3_N</th>\n",
       "      <th>Head</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=CCCCCC(C)CCCCCC#CCCC(OC)C(=O)OC(=O)C(CCC#CCC...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(CO)OC(=O)CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCCCCCC[C@H](O)CC(=O)N[C@@H](CO)C(=O)O</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(CCO)N[C@@H](CO)C(=O)O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCCCC)CC(=O)N[...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>1</td>\n",
       "      <td>NCCC[C@H](NC(=O)CCOC=O)C(=O)O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC/C=C\\C/C=C\\C/C=C\\CCCCCCCC(=O)N[C@@H](CCC(N)=...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>NC(=O)CC[C@H](NC=O)C(=O)O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)CCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCC(C)C)CC(...</td>\n",
       "      <td>Fatty Acyls</td>\n",
       "      <td>0</td>\n",
       "      <td>O=COCCC(=O)N[C@@H](CO)C(=O)O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47065</th>\n",
       "      <td>CCCCCCCCCCC[C@H](CC1=CC(=O)C=C(OC)C1=O)OC(C)=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=COCCC1=CC(=O)C=C(O)C1=O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47066</th>\n",
       "      <td>CCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47067</th>\n",
       "      <td>CCCCCCCCCCCC1=C(O)C(=O)C=C(OC)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47068</th>\n",
       "      <td>CCCCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47069</th>\n",
       "      <td>CCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O</td>\n",
       "      <td>Polyketides</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C1C=C(O)C(=O)C=C1O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47070 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SMILES     Category  SP3_N  \\\n",
       "0      C=CCCCCC(C)CCCCCC#CCCC(OC)C(=O)OC(=O)C(CCC#CCC...  Fatty Acyls      0   \n",
       "1                 CCCCCCC[C@H](O)CC(=O)N[C@@H](CO)C(=O)O  Fatty Acyls      0   \n",
       "2      CCCCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCCCC)CC(=O)N[...  Fatty Acyls      1   \n",
       "3      CC/C=C\\C/C=C\\C/C=C\\CCCCCCCC(=O)N[C@@H](CCC(N)=...  Fatty Acyls      0   \n",
       "4      CC(C)CCCCCCCCCCCCCC(=O)OC(CCCCCCCCCCCC(C)C)CC(...  Fatty Acyls      0   \n",
       "...                                                  ...          ...    ...   \n",
       "47065     CCCCCCCCCCC[C@H](CC1=CC(=O)C=C(OC)C1=O)OC(C)=O  Polyketides      0   \n",
       "47066                  CCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "47067                 CCCCCCCCCCCC1=C(O)C(=O)C=C(OC)C1=O  Polyketides      0   \n",
       "47068              CCCCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "47069                CCCCCCCCCCCCCC1=C(O)C(=O)C=C(O)C1=O  Polyketides      0   \n",
       "\n",
       "                                Head  Class  \n",
       "0                    O=C(CO)OC(=O)CO      0  \n",
       "1          O=C(CCO)N[C@@H](CO)C(=O)O      0  \n",
       "2      NCCC[C@H](NC(=O)CCOC=O)C(=O)O      0  \n",
       "3          NC(=O)CC[C@H](NC=O)C(=O)O      0  \n",
       "4       O=COCCC(=O)N[C@@H](CO)C(=O)O      0  \n",
       "...                              ...    ...  \n",
       "47065      O=COCCC1=CC(=O)C=C(O)C1=O      7  \n",
       "47066           O=C1C=C(O)C(=O)C=C1O      7  \n",
       "47067           O=C1C=C(O)C(=O)C=C1O      7  \n",
       "47068           O=C1C=C(O)C(=O)C=C1O      7  \n",
       "47069           O=C1C=C(O)C(=O)C=C1O      7  \n",
       "\n",
       "[47070 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {c:i for i,c in enumerate(df['Category'].unique())}\n",
    "# df['Head'] = 0\n",
    "df['Class'] = 0\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "#     df.loc[i, 'Head'] = get_head(df['SMILES'].iloc[i])\n",
    "    df.loc[i, 'Class'] = classes[df['Category'].iloc[i]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:23.502688Z",
     "iopub.status.busy": "2022-11-16T13:56:23.502481Z",
     "iopub.status.idle": "2022-11-16T13:56:23.509831Z",
     "shell.execute_reply": "2022-11-16T13:56:23.509243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37656, 9414)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(df, \n",
    "                                   test_size=0.2, \n",
    "                                   shuffle=True, \n",
    "                                   random_state=args.seed)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:23.512452Z",
     "iopub.status.busy": "2022-11-16T13:56:23.511829Z",
     "iopub.status.idle": "2022-11-16T13:56:24.663103Z",
     "shell.execute_reply": "2022-11-16T13:56:24.661886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37656, 9414)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total_mols = make_mol(X_train, 'SMILES')\n",
    "train_head_mols = make_mol(X_train, 'Head')\n",
    "test_total_mols = make_mol(X_test, 'SMILES')\n",
    "test_head_mols = make_mol(X_test, 'Head')\n",
    "\n",
    "train_total_X = make_vec(train_total_mols)\n",
    "train_head_X = make_vec(train_head_mols)\n",
    "test_total_X = make_vec(test_total_mols)\n",
    "test_head_X = make_vec(test_head_mols)\n",
    "\n",
    "train_X = []\n",
    "for total, head in zip(train_total_X, train_head_X):\n",
    "    train_X.append([total, head])\n",
    "\n",
    "test_X = []\n",
    "for total, head in zip(test_total_X, test_head_X):\n",
    "    test_X.append([total, head])\n",
    "\n",
    "len(train_X), len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:24.666583Z",
     "iopub.status.busy": "2022-11-16T13:56:24.666359Z",
     "iopub.status.idle": "2022-11-16T13:56:24.678857Z",
     "shell.execute_reply": "2022-11-16T13:56:24.678390Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNlayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, conv_dim1, conv_dim2, conv_dim3, concat_dim, dropout):\n",
    "        super(GCNlayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = GCNConv(n_features, conv_dim1)\n",
    "        self.bn1 = BatchNorm1d(conv_dim1)\n",
    "        self.conv2 = GCNConv(conv_dim1, conv_dim2)\n",
    "        self.bn2 = BatchNorm1d(conv_dim2)\n",
    "        self.conv3 = GCNConv(conv_dim2, conv_dim3)\n",
    "        self.bn3 = BatchNorm1d(conv_dim3)\n",
    "        self.conv4 = GCNConv(conv_dim3, concat_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(self.bn1(x), p=self.dropout)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(self.bn2(x), p=self.dropout)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(self.bn3(x), p=self.dropout)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = global_add_pool(x, data.batch)\n",
    "        return x\n",
    "    \n",
    "class FClayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, concat_dim, pred_dim1, pred_dim2, pred_dim3, out_dim, dropout):\n",
    "        super(FClayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.fc1 = Linear(concat_dim, pred_dim1)\n",
    "        self.bn1 = BatchNorm1d(pred_dim1)\n",
    "        self.fc2 = Linear(pred_dim1, pred_dim2)\n",
    "        self.bn2 = BatchNorm1d(pred_dim2)\n",
    "        self.fc3 = Linear(pred_dim2, pred_dim3)\n",
    "        self.bn3 = BatchNorm1d(pred_dim3)\n",
    "        self.fc4 = Linear(pred_dim3, out_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.fc1(data))\n",
    "        x = F.dropout(self.bn1(x), p=self.dropout)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(self.bn2(x), p=self.dropout)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(self.bn3(x), p=self.dropout)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Net, self).__init__()\n",
    "        self.total_conv = GCNlayer(args.n_features, \n",
    "                                   args.conv_dim1, \n",
    "                                   args.conv_dim2, \n",
    "                                   args.conv_dim3, \n",
    "                                   args.concat_dim, \n",
    "                                   args.dropout)\n",
    "        self.head_conv = GCNlayer(args.n_features, \n",
    "                                  args.conv_dim1, \n",
    "                                  args.conv_dim2, \n",
    "                                  args.conv_dim3, \n",
    "                                  args.concat_dim, \n",
    "                                  args.dropout)\n",
    "        self.fc = FClayer(args.concat_dim*2, \n",
    "                          args.pred_dim1, \n",
    "                          args.pred_dim2, \n",
    "                          args.pred_dim3, \n",
    "                          args.out_dim, \n",
    "                          args.dropout)\n",
    "        \n",
    "    def forward(self, total, head):\n",
    "        total_x = self.total_conv(total)\n",
    "        head_x = self.head_conv(head)\n",
    "        x = torch.cat((total_x, head_x), dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:24.681386Z",
     "iopub.status.busy": "2022-11-16T13:56:24.680870Z",
     "iopub.status.idle": "2022-11-16T13:56:24.692975Z",
     "shell.execute_reply": "2022-11-16T13:56:24.692528Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, train_loader, criterion, args, prints):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "    for i, [total, head] in enumerate(train_loader):\n",
    "        total = total.to(device)\n",
    "        head = head.to(device)\n",
    "        labels = total.y.to(device)\n",
    "        outputs = model(total, head)\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        y_pred.extend(outputs.cpu().detach().max(axis=1).indices.tolist())\n",
    "        y_true.extend(labels.cpu().detach().tolist())\n",
    "    epoch_loss /= len(train_loader)\n",
    "    return model, epoch_loss.tolist(), y_true, y_pred\n",
    "\n",
    "def test(model, device, test_loader, criterion, args, prints):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, [total, head] in enumerate(test_loader):\n",
    "            total = total.to(device)\n",
    "            head = head.to(device)\n",
    "            labels = total.y.to(device)\n",
    "            outputs = model(total, head)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss\n",
    "            y_pred.extend(outputs.cpu().detach().max(axis=1).indices.tolist())\n",
    "            y_true.extend(labels.cpu().detach().tolist())\n",
    "    epoch_loss /= len(train_loader)\n",
    "    return model, epoch_loss.tolist(), y_true, y_pred\n",
    "\n",
    "def results(true, pred):\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    acc = accuracy_score(true, pred)\n",
    "    micf1 = f1_score(true, pred, average='micro')\n",
    "    macf1 = f1_score(true, pred, average='macro')\n",
    "    print('Accuracy : %.2f' % acc)\n",
    "    print('Micro F1 Score : %.2f' % micf1)\n",
    "    print('Macro F1 Score : %.2f' % macf1)\n",
    "    return cm, acc, micf1, macf1\n",
    "\n",
    "def experiment(model, train_loader, test_loader, device, args, prints=True):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(),lr=args.lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                          step_size=args.step_size,\n",
    "                                          gamma=args.gamma)\n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    \n",
    "    list_train_loss = []\n",
    "    list_test_loss = []\n",
    "    if prints:\n",
    "        print('[Train]')\n",
    "    for epoch in range(args.epoch):\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        model, train_loss, _, _ = train(model, device, optimizer, train_loader, criterion, args, prints)\n",
    "        model, test_loss, y_true, y_pred = test(model, device, test_loader, criterion, args, prints)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_test_loss.append(test_loss)\n",
    "        if prints:\n",
    "            print('- Epoch: %d\\t- Train Loss: %.4f\\t- Test Loss: %.4f' % (epoch+1, train_loss, test_loss))\n",
    "        early_stopping(test_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    if prints:\n",
    "        print('[Tets]')\n",
    "    model, test_loss, y_true, y_pred = test(model, device, test_loader, criterion, args, prints)\n",
    "    \n",
    "    cm, acc, micf1, macf1 = results(y_true, y_pred)\n",
    "    \n",
    "    args.list_train_loss = list_train_loss\n",
    "    args.list_test_loss = list_test_loss\n",
    "    args.y_true = y_true\n",
    "    args.y_pred = y_pred\n",
    "    args.cm = cm\n",
    "    args.acc = acc\n",
    "    args.micf1 = micf1\n",
    "    args.macf1 = macf1\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:24.695429Z",
     "iopub.status.busy": "2022-11-16T13:56:24.694915Z",
     "iopub.status.idle": "2022-11-16T13:56:24.702740Z",
     "shell.execute_reply": "2022-11-16T13:56:24.702318Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_result(result_df):\n",
    "    \n",
    "    figsize = 4\n",
    "    label_fs = 14\n",
    "    legend_fs = 12\n",
    "    ticks_fs = 12\n",
    "\n",
    "    train_loss = result_df['list_train_loss'].iloc[0]\n",
    "    test_loss = result_df['list_test_loss'].iloc[0]\n",
    "    y_true = result_df['y_true'].iloc[0]\n",
    "    y_pred = result_df['y_pred'].iloc[0]\n",
    "    classes = result_df['classes'].iloc[0]\n",
    "    cm, acc, micf1, macf1 = results(y_true, y_pred)\n",
    "    \n",
    "    cm_matrix = pd.DataFrame(cm, \n",
    "                             index=classes, \n",
    "                             columns=classes)\n",
    "    plt.figure(figsize=(figsize+1, figsize))\n",
    "    sns.heatmap(cm_matrix.astype('int'), annot=True, cmap='Blues', fmt=\"d\", \n",
    "               xticklabels=classes, yticklabels=classes, annot_kws={\"size\": 8})\n",
    "    plt.tick_params(left=False, bottom=False)\n",
    "    plt.xlabel('Predicted Class', fontsize=label_fs)\n",
    "    plt.ylabel('True Class', fontsize=label_fs)\n",
    "    plt.xticks(fontsize=ticks_fs)\n",
    "    plt.yticks(fontsize=ticks_fs)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.plot([e for e in range(len(train_loss))], [float(t) for t in train_loss], label=\"Train Loss\", c='blue')\n",
    "    plt.plot([e for e in range(len(train_loss))], [float(t) for t in test_loss], label=\"Test Loss\", c='red')\n",
    "    plt.xlabel(\"Epoch\", fontsize=label_fs)\n",
    "    plt.ylabel(\"Loss\", fontsize=label_fs)\n",
    "    plt.xticks(fontsize=ticks_fs)\n",
    "    plt.yticks(fontsize=ticks_fs)\n",
    "    plt.legend(fontsize=legend_fs)\n",
    "    plt.show()\n",
    "    \n",
    "    return cm, acc, micf1, macf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-16T13:56:24.705230Z",
     "iopub.status.busy": "2022-11-16T13:56:24.704617Z",
     "iopub.status.idle": "2022-11-16T15:14:28.350619Z",
     "shell.execute_reply": "2022-11-16T15:14:28.349851Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      "- Epoch: 1\t- Train Loss: 2.2829\t- Test Loss: 0.5749\n",
      "- Epoch: 2\t- Train Loss: 2.1675\t- Test Loss: 0.5570\n",
      "- Epoch: 3\t- Train Loss: 2.0761\t- Test Loss: 0.5309\n",
      "- Epoch: 4\t- Train Loss: 1.9853\t- Test Loss: 0.5117\n",
      "- Epoch: 5\t- Train Loss: 1.9093\t- Test Loss: 0.4929\n",
      "- Epoch: 6\t- Train Loss: 1.8337\t- Test Loss: 0.4715\n",
      "- Epoch: 7\t- Train Loss: 1.7671\t- Test Loss: 0.4538\n",
      "- Epoch: 8\t- Train Loss: 1.7016\t- Test Loss: 0.4384\n",
      "- Epoch: 9\t- Train Loss: 1.6416\t- Test Loss: 0.4195\n",
      "- Epoch: 10\t- Train Loss: 1.5961\t- Test Loss: 0.4091\n",
      "- Epoch: 11\t- Train Loss: 1.5565\t- Test Loss: 0.3993\n",
      "- Epoch: 12\t- Train Loss: 1.5194\t- Test Loss: 0.3883\n",
      "- Epoch: 13\t- Train Loss: 1.4834\t- Test Loss: 0.3809\n",
      "- Epoch: 14\t- Train Loss: 1.4419\t- Test Loss: 0.3721\n",
      "- Epoch: 15\t- Train Loss: 1.4110\t- Test Loss: 0.3638\n",
      "- Epoch: 16\t- Train Loss: 1.3820\t- Test Loss: 0.3567\n",
      "- Epoch: 17\t- Train Loss: 1.3500\t- Test Loss: 0.3480\n",
      "- Epoch: 18\t- Train Loss: 1.3303\t- Test Loss: 0.3403\n",
      "- Epoch: 19\t- Train Loss: 1.3003\t- Test Loss: 0.3315\n",
      "- Epoch: 20\t- Train Loss: 1.2735\t- Test Loss: 0.3275\n",
      "- Epoch: 21\t- Train Loss: 1.2477\t- Test Loss: 0.3212\n",
      "- Epoch: 22\t- Train Loss: 1.2298\t- Test Loss: 0.3150\n",
      "- Epoch: 23\t- Train Loss: 1.2046\t- Test Loss: 0.3102\n",
      "- Epoch: 24\t- Train Loss: 1.1780\t- Test Loss: 0.3065\n",
      "- Epoch: 25\t- Train Loss: 1.1623\t- Test Loss: 0.2979\n",
      "- Epoch: 26\t- Train Loss: 1.1369\t- Test Loss: 0.2916\n",
      "- Epoch: 27\t- Train Loss: 1.1252\t- Test Loss: 0.2865\n",
      "- Epoch: 28\t- Train Loss: 1.0947\t- Test Loss: 0.2796\n",
      "- Epoch: 29\t- Train Loss: 1.0771\t- Test Loss: 0.2766\n",
      "- Epoch: 30\t- Train Loss: 1.0581\t- Test Loss: 0.2710\n",
      "- Epoch: 31\t- Train Loss: 1.0401\t- Test Loss: 0.2672\n",
      "- Epoch: 32\t- Train Loss: 1.0283\t- Test Loss: 0.2622\n",
      "- Epoch: 33\t- Train Loss: 1.0141\t- Test Loss: 0.2600\n",
      "- Epoch: 34\t- Train Loss: 0.9997\t- Test Loss: 0.2562\n",
      "- Epoch: 35\t- Train Loss: 0.9864\t- Test Loss: 0.2544\n",
      "- Epoch: 36\t- Train Loss: 0.9678\t- Test Loss: 0.2485\n",
      "- Epoch: 37\t- Train Loss: 0.9549\t- Test Loss: 0.2450\n",
      "- Epoch: 38\t- Train Loss: 0.9350\t- Test Loss: 0.2411\n",
      "- Epoch: 39\t- Train Loss: 0.9205\t- Test Loss: 0.2359\n",
      "- Epoch: 40\t- Train Loss: 0.9144\t- Test Loss: 0.2354\n",
      "- Epoch: 41\t- Train Loss: 0.9049\t- Test Loss: 0.2302\n",
      "- Epoch: 42\t- Train Loss: 0.8973\t- Test Loss: 0.2292\n",
      "- Epoch: 43\t- Train Loss: 0.8897\t- Test Loss: 0.2264\n",
      "- Epoch: 44\t- Train Loss: 0.8719\t- Test Loss: 0.2244\n",
      "- Epoch: 45\t- Train Loss: 0.8584\t- Test Loss: 0.2222\n",
      "- Epoch: 46\t- Train Loss: 0.8511\t- Test Loss: 0.2172\n",
      "- Epoch: 47\t- Train Loss: 0.8411\t- Test Loss: 0.2141\n",
      "- Epoch: 48\t- Train Loss: 0.8312\t- Test Loss: 0.2096\n",
      "- Epoch: 49\t- Train Loss: 0.8209\t- Test Loss: 0.2083\n",
      "- Epoch: 50\t- Train Loss: 0.8067\t- Test Loss: 0.2059\n",
      "- Epoch: 51\t- Train Loss: 0.8005\t- Test Loss: 0.2043\n",
      "- Epoch: 52\t- Train Loss: 0.7897\t- Test Loss: 0.2028\n",
      "- Epoch: 53\t- Train Loss: 0.7919\t- Test Loss: 0.2004\n",
      "- Epoch: 54\t- Train Loss: 0.7758\t- Test Loss: 0.1982\n",
      "- Epoch: 55\t- Train Loss: 0.7715\t- Test Loss: 0.1953\n",
      "- Epoch: 56\t- Train Loss: 0.7690\t- Test Loss: 0.2002\n",
      "- Epoch: 57\t- Train Loss: 0.7528\t- Test Loss: 0.1908\n",
      "- Epoch: 58\t- Train Loss: 0.7434\t- Test Loss: 0.1931\n",
      "- Epoch: 59\t- Train Loss: 0.7430\t- Test Loss: 0.1917\n",
      "- Epoch: 60\t- Train Loss: 0.7360\t- Test Loss: 0.1896\n",
      "- Epoch: 61\t- Train Loss: 0.7267\t- Test Loss: 0.1877\n",
      "- Epoch: 62\t- Train Loss: 0.7200\t- Test Loss: 0.1849\n",
      "- Epoch: 63\t- Train Loss: 0.7139\t- Test Loss: 0.1829\n",
      "- Epoch: 64\t- Train Loss: 0.7075\t- Test Loss: 0.1804\n",
      "- Epoch: 65\t- Train Loss: 0.7051\t- Test Loss: 0.1815\n",
      "- Epoch: 66\t- Train Loss: 0.6997\t- Test Loss: 0.1804\n",
      "- Epoch: 67\t- Train Loss: 0.6954\t- Test Loss: 0.1766\n",
      "- Epoch: 68\t- Train Loss: 0.6942\t- Test Loss: 0.1742\n",
      "- Epoch: 69\t- Train Loss: 0.6809\t- Test Loss: 0.1762\n",
      "- Epoch: 70\t- Train Loss: 0.6877\t- Test Loss: 0.1736\n",
      "- Epoch: 71\t- Train Loss: 0.6749\t- Test Loss: 0.1722\n",
      "- Epoch: 72\t- Train Loss: 0.6693\t- Test Loss: 0.1723\n",
      "- Epoch: 73\t- Train Loss: 0.6688\t- Test Loss: 0.1699\n",
      "- Epoch: 74\t- Train Loss: 0.6677\t- Test Loss: 0.1713\n",
      "- Epoch: 75\t- Train Loss: 0.6598\t- Test Loss: 0.1711\n",
      "- Epoch: 76\t- Train Loss: 0.6518\t- Test Loss: 0.1654\n",
      "- Epoch: 77\t- Train Loss: 0.6501\t- Test Loss: 0.1645\n",
      "- Epoch: 78\t- Train Loss: 0.6472\t- Test Loss: 0.1638\n",
      "- Epoch: 79\t- Train Loss: 0.6415\t- Test Loss: 0.1632\n",
      "- Epoch: 80\t- Train Loss: 0.6396\t- Test Loss: 0.1632\n",
      "- Epoch: 81\t- Train Loss: 0.6370\t- Test Loss: 0.1606\n",
      "- Epoch: 82\t- Train Loss: 0.6312\t- Test Loss: 0.1602\n",
      "- Epoch: 83\t- Train Loss: 0.6273\t- Test Loss: 0.1614\n",
      "- Epoch: 84\t- Train Loss: 0.6235\t- Test Loss: 0.1606\n",
      "- Epoch: 85\t- Train Loss: 0.6203\t- Test Loss: 0.1595\n",
      "- Epoch: 86\t- Train Loss: 0.6148\t- Test Loss: 0.1576\n",
      "- Epoch: 87\t- Train Loss: 0.6132\t- Test Loss: 0.1551\n",
      "- Epoch: 88\t- Train Loss: 0.6072\t- Test Loss: 0.1534\n",
      "- Epoch: 89\t- Train Loss: 0.6046\t- Test Loss: 0.1544\n",
      "- Epoch: 90\t- Train Loss: 0.6064\t- Test Loss: 0.1515\n",
      "- Epoch: 91\t- Train Loss: 0.5989\t- Test Loss: 0.1511\n",
      "- Epoch: 92\t- Train Loss: 0.5938\t- Test Loss: 0.1548\n",
      "- Epoch: 93\t- Train Loss: 0.5930\t- Test Loss: 0.1509\n",
      "- Epoch: 94\t- Train Loss: 0.5917\t- Test Loss: 0.1481\n",
      "- Epoch: 95\t- Train Loss: 0.5826\t- Test Loss: 0.1485\n",
      "- Epoch: 96\t- Train Loss: 0.5793\t- Test Loss: 0.1478\n",
      "- Epoch: 97\t- Train Loss: 0.5806\t- Test Loss: 0.1463\n",
      "- Epoch: 98\t- Train Loss: 0.5808\t- Test Loss: 0.1468\n",
      "- Epoch: 99\t- Train Loss: 0.5790\t- Test Loss: 0.1454\n",
      "- Epoch: 100\t- Train Loss: 0.5719\t- Test Loss: 0.1443\n",
      "- Epoch: 101\t- Train Loss: 0.5714\t- Test Loss: 0.1461\n",
      "- Epoch: 102\t- Train Loss: 0.5741\t- Test Loss: 0.1452\n",
      "- Epoch: 103\t- Train Loss: 0.5700\t- Test Loss: 0.1464\n",
      "- Epoch: 104\t- Train Loss: 0.5607\t- Test Loss: 0.1443\n",
      "- Epoch: 105\t- Train Loss: 0.5655\t- Test Loss: 0.1446\n",
      "- Epoch: 106\t- Train Loss: 0.5574\t- Test Loss: 0.1430\n",
      "- Epoch: 107\t- Train Loss: 0.5586\t- Test Loss: 0.1420\n",
      "- Epoch: 108\t- Train Loss: 0.5547\t- Test Loss: 0.1414\n",
      "- Epoch: 109\t- Train Loss: 0.5479\t- Test Loss: 0.1419\n",
      "- Epoch: 110\t- Train Loss: 0.5475\t- Test Loss: 0.1394\n",
      "- Epoch: 111\t- Train Loss: 0.5495\t- Test Loss: 0.1380\n",
      "- Epoch: 112\t- Train Loss: 0.5454\t- Test Loss: 0.1422\n",
      "- Epoch: 113\t- Train Loss: 0.5466\t- Test Loss: 0.1386\n",
      "- Epoch: 114\t- Train Loss: 0.5422\t- Test Loss: 0.1407\n",
      "- Epoch: 115\t- Train Loss: 0.5433\t- Test Loss: 0.1379\n",
      "- Epoch: 116\t- Train Loss: 0.5435\t- Test Loss: 0.1365\n",
      "- Epoch: 117\t- Train Loss: 0.5379\t- Test Loss: 0.1380\n",
      "- Epoch: 118\t- Train Loss: 0.5406\t- Test Loss: 0.1367\n",
      "- Epoch: 119\t- Train Loss: 0.5313\t- Test Loss: 0.1343\n",
      "- Epoch: 120\t- Train Loss: 0.5319\t- Test Loss: 0.1371\n",
      "- Epoch: 121\t- Train Loss: 0.5293\t- Test Loss: 0.1366\n",
      "- Epoch: 122\t- Train Loss: 0.5297\t- Test Loss: 0.1348\n",
      "- Epoch: 123\t- Train Loss: 0.5283\t- Test Loss: 0.1348\n",
      "- Epoch: 124\t- Train Loss: 0.5238\t- Test Loss: 0.1325\n",
      "- Epoch: 125\t- Train Loss: 0.5251\t- Test Loss: 0.1335\n",
      "- Epoch: 126\t- Train Loss: 0.5176\t- Test Loss: 0.1315\n",
      "- Epoch: 127\t- Train Loss: 0.5220\t- Test Loss: 0.1318\n",
      "- Epoch: 128\t- Train Loss: 0.5212\t- Test Loss: 0.1327\n",
      "- Epoch: 129\t- Train Loss: 0.5204\t- Test Loss: 0.1312\n",
      "- Epoch: 130\t- Train Loss: 0.5153\t- Test Loss: 0.1317\n",
      "- Epoch: 131\t- Train Loss: 0.5151\t- Test Loss: 0.1315\n",
      "- Epoch: 132\t- Train Loss: 0.5111\t- Test Loss: 0.1335\n",
      "- Epoch: 133\t- Train Loss: 0.5120\t- Test Loss: 0.1307\n",
      "- Epoch: 134\t- Train Loss: 0.5144\t- Test Loss: 0.1307\n",
      "- Epoch: 135\t- Train Loss: 0.5085\t- Test Loss: 0.1310\n",
      "- Epoch: 136\t- Train Loss: 0.5048\t- Test Loss: 0.1264\n",
      "- Epoch: 137\t- Train Loss: 0.5072\t- Test Loss: 0.1294\n",
      "- Epoch: 138\t- Train Loss: 0.5059\t- Test Loss: 0.1303\n",
      "- Epoch: 139\t- Train Loss: 0.5047\t- Test Loss: 0.1286\n",
      "- Epoch: 140\t- Train Loss: 0.5043\t- Test Loss: 0.1281\n",
      "- Epoch: 141\t- Train Loss: 0.5025\t- Test Loss: 0.1252\n",
      "- Epoch: 142\t- Train Loss: 0.5040\t- Test Loss: 0.1248\n",
      "- Epoch: 143\t- Train Loss: 0.4964\t- Test Loss: 0.1235\n",
      "- Epoch: 144\t- Train Loss: 0.4974\t- Test Loss: 0.1287\n",
      "- Epoch: 145\t- Train Loss: 0.4939\t- Test Loss: 0.1245\n",
      "- Epoch: 146\t- Train Loss: 0.4980\t- Test Loss: 0.1275\n",
      "- Epoch: 147\t- Train Loss: 0.4956\t- Test Loss: 0.1280\n",
      "- Epoch: 148\t- Train Loss: 0.4955\t- Test Loss: 0.1234\n",
      "- Epoch: 149\t- Train Loss: 0.4901\t- Test Loss: 0.1227\n",
      "- Epoch: 150\t- Train Loss: 0.4909\t- Test Loss: 0.1250\n",
      "- Epoch: 151\t- Train Loss: 0.4920\t- Test Loss: 0.1258\n",
      "- Epoch: 152\t- Train Loss: 0.4894\t- Test Loss: 0.1263\n",
      "- Epoch: 153\t- Train Loss: 0.4859\t- Test Loss: 0.1239\n",
      "- Epoch: 154\t- Train Loss: 0.4866\t- Test Loss: 0.1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch: 155\t- Train Loss: 0.4842\t- Test Loss: 0.1233\n",
      "- Epoch: 156\t- Train Loss: 0.4850\t- Test Loss: 0.1227\n",
      "- Epoch: 157\t- Train Loss: 0.4862\t- Test Loss: 0.1233\n",
      "- Epoch: 158\t- Train Loss: 0.4828\t- Test Loss: 0.1211\n",
      "- Epoch: 159\t- Train Loss: 0.4834\t- Test Loss: 0.1222\n",
      "- Epoch: 160\t- Train Loss: 0.4801\t- Test Loss: 0.1235\n",
      "- Epoch: 161\t- Train Loss: 0.4802\t- Test Loss: 0.1242\n",
      "- Epoch: 162\t- Train Loss: 0.4814\t- Test Loss: 0.1204\n",
      "- Epoch: 163\t- Train Loss: 0.4790\t- Test Loss: 0.1215\n",
      "- Epoch: 164\t- Train Loss: 0.4778\t- Test Loss: 0.1227\n",
      "- Epoch: 165\t- Train Loss: 0.4750\t- Test Loss: 0.1231\n",
      "- Epoch: 166\t- Train Loss: 0.4740\t- Test Loss: 0.1218\n",
      "- Epoch: 167\t- Train Loss: 0.4733\t- Test Loss: 0.1190\n",
      "- Epoch: 168\t- Train Loss: 0.4716\t- Test Loss: 0.1223\n",
      "- Epoch: 169\t- Train Loss: 0.4713\t- Test Loss: 0.1201\n",
      "- Epoch: 170\t- Train Loss: 0.4682\t- Test Loss: 0.1225\n",
      "- Epoch: 171\t- Train Loss: 0.4743\t- Test Loss: 0.1189\n",
      "- Epoch: 172\t- Train Loss: 0.4691\t- Test Loss: 0.1204\n",
      "- Epoch: 173\t- Train Loss: 0.4696\t- Test Loss: 0.1201\n",
      "- Epoch: 174\t- Train Loss: 0.4690\t- Test Loss: 0.1213\n",
      "- Epoch: 175\t- Train Loss: 0.4689\t- Test Loss: 0.1185\n",
      "- Epoch: 176\t- Train Loss: 0.4693\t- Test Loss: 0.1191\n",
      "- Epoch: 177\t- Train Loss: 0.4656\t- Test Loss: 0.1197\n",
      "- Epoch: 178\t- Train Loss: 0.4605\t- Test Loss: 0.1172\n",
      "- Epoch: 179\t- Train Loss: 0.4671\t- Test Loss: 0.1201\n",
      "- Epoch: 180\t- Train Loss: 0.4650\t- Test Loss: 0.1172\n",
      "- Epoch: 181\t- Train Loss: 0.4596\t- Test Loss: 0.1187\n",
      "- Epoch: 182\t- Train Loss: 0.4640\t- Test Loss: 0.1187\n",
      "- Epoch: 183\t- Train Loss: 0.4594\t- Test Loss: 0.1193\n",
      "- Epoch: 184\t- Train Loss: 0.4635\t- Test Loss: 0.1167\n",
      "- Epoch: 185\t- Train Loss: 0.4583\t- Test Loss: 0.1179\n",
      "- Epoch: 186\t- Train Loss: 0.4593\t- Test Loss: 0.1170\n",
      "- Epoch: 187\t- Train Loss: 0.4586\t- Test Loss: 0.1174\n",
      "- Epoch: 188\t- Train Loss: 0.4607\t- Test Loss: 0.1155\n",
      "- Epoch: 189\t- Train Loss: 0.4584\t- Test Loss: 0.1146\n",
      "- Epoch: 190\t- Train Loss: 0.4570\t- Test Loss: 0.1159\n",
      "- Epoch: 191\t- Train Loss: 0.4617\t- Test Loss: 0.1162\n",
      "- Epoch: 192\t- Train Loss: 0.4557\t- Test Loss: 0.1200\n",
      "- Epoch: 193\t- Train Loss: 0.4591\t- Test Loss: 0.1174\n",
      "- Epoch: 194\t- Train Loss: 0.4581\t- Test Loss: 0.1185\n",
      "- Epoch: 195\t- Train Loss: 0.4579\t- Test Loss: 0.1147\n",
      "- Epoch: 196\t- Train Loss: 0.4559\t- Test Loss: 0.1175\n",
      "- Epoch: 197\t- Train Loss: 0.4517\t- Test Loss: 0.1169\n",
      "- Epoch: 198\t- Train Loss: 0.4518\t- Test Loss: 0.1163\n",
      "- Epoch: 199\t- Train Loss: 0.4535\t- Test Loss: 0.1131\n",
      "- Epoch: 200\t- Train Loss: 0.4502\t- Test Loss: 0.1144\n",
      "- Epoch: 201\t- Train Loss: 0.4507\t- Test Loss: 0.1156\n",
      "- Epoch: 202\t- Train Loss: 0.4483\t- Test Loss: 0.1177\n",
      "- Epoch: 203\t- Train Loss: 0.4528\t- Test Loss: 0.1154\n",
      "- Epoch: 204\t- Train Loss: 0.4487\t- Test Loss: 0.1135\n",
      "- Epoch: 205\t- Train Loss: 0.4504\t- Test Loss: 0.1139\n",
      "- Epoch: 206\t- Train Loss: 0.4496\t- Test Loss: 0.1142\n",
      "- Epoch: 207\t- Train Loss: 0.4445\t- Test Loss: 0.1142\n",
      "- Epoch: 208\t- Train Loss: 0.4460\t- Test Loss: 0.1147\n",
      "- Epoch: 209\t- Train Loss: 0.4497\t- Test Loss: 0.1140\n",
      "- Epoch: 210\t- Train Loss: 0.4471\t- Test Loss: 0.1104\n",
      "- Epoch: 211\t- Train Loss: 0.4463\t- Test Loss: 0.1131\n",
      "- Epoch: 212\t- Train Loss: 0.4432\t- Test Loss: 0.1123\n",
      "- Epoch: 213\t- Train Loss: 0.4440\t- Test Loss: 0.1133\n",
      "- Epoch: 214\t- Train Loss: 0.4447\t- Test Loss: 0.1119\n",
      "- Epoch: 215\t- Train Loss: 0.4454\t- Test Loss: 0.1127\n",
      "- Epoch: 216\t- Train Loss: 0.4447\t- Test Loss: 0.1149\n",
      "- Epoch: 217\t- Train Loss: 0.4438\t- Test Loss: 0.1109\n",
      "- Epoch: 218\t- Train Loss: 0.4464\t- Test Loss: 0.1132\n",
      "- Epoch: 219\t- Train Loss: 0.4436\t- Test Loss: 0.1117\n",
      "- Epoch: 220\t- Train Loss: 0.4407\t- Test Loss: 0.1147\n",
      "- Epoch: 221\t- Train Loss: 0.4474\t- Test Loss: 0.1129\n",
      "- Epoch: 222\t- Train Loss: 0.4416\t- Test Loss: 0.1143\n",
      "- Epoch: 223\t- Train Loss: 0.4407\t- Test Loss: 0.1114\n",
      "- Epoch: 224\t- Train Loss: 0.4408\t- Test Loss: 0.1134\n",
      "- Epoch: 225\t- Train Loss: 0.4403\t- Test Loss: 0.1139\n",
      "- Epoch: 226\t- Train Loss: 0.4342\t- Test Loss: 0.1121\n",
      "- Epoch: 227\t- Train Loss: 0.4411\t- Test Loss: 0.1124\n",
      "- Epoch: 228\t- Train Loss: 0.4394\t- Test Loss: 0.1123\n",
      "- Epoch: 229\t- Train Loss: 0.4356\t- Test Loss: 0.1129\n",
      "- Epoch: 230\t- Train Loss: 0.4383\t- Test Loss: 0.1119\n",
      "- Epoch: 231\t- Train Loss: 0.4408\t- Test Loss: 0.1127\n",
      "- Epoch: 232\t- Train Loss: 0.4394\t- Test Loss: 0.1122\n",
      "- Epoch: 233\t- Train Loss: 0.4411\t- Test Loss: 0.1130\n",
      "- Epoch: 234\t- Train Loss: 0.4377\t- Test Loss: 0.1130\n",
      "- Epoch: 235\t- Train Loss: 0.4334\t- Test Loss: 0.1121\n",
      "- Epoch: 236\t- Train Loss: 0.4292\t- Test Loss: 0.1108\n",
      "- Epoch: 237\t- Train Loss: 0.4355\t- Test Loss: 0.1117\n",
      "- Epoch: 238\t- Train Loss: 0.4369\t- Test Loss: 0.1092\n",
      "- Epoch: 239\t- Train Loss: 0.4329\t- Test Loss: 0.1114\n",
      "- Epoch: 240\t- Train Loss: 0.4351\t- Test Loss: 0.1137\n",
      "- Epoch: 241\t- Train Loss: 0.4340\t- Test Loss: 0.1093\n",
      "- Epoch: 242\t- Train Loss: 0.4341\t- Test Loss: 0.1102\n",
      "- Epoch: 243\t- Train Loss: 0.4385\t- Test Loss: 0.1091\n",
      "- Epoch: 244\t- Train Loss: 0.4333\t- Test Loss: 0.1109\n",
      "- Epoch: 245\t- Train Loss: 0.4366\t- Test Loss: 0.1116\n",
      "- Epoch: 246\t- Train Loss: 0.4314\t- Test Loss: 0.1086\n",
      "- Epoch: 247\t- Train Loss: 0.4344\t- Test Loss: 0.1096\n",
      "- Epoch: 248\t- Train Loss: 0.4316\t- Test Loss: 0.1109\n",
      "- Epoch: 249\t- Train Loss: 0.4322\t- Test Loss: 0.1104\n",
      "- Epoch: 250\t- Train Loss: 0.4349\t- Test Loss: 0.1119\n",
      "- Epoch: 251\t- Train Loss: 0.4306\t- Test Loss: 0.1083\n",
      "- Epoch: 252\t- Train Loss: 0.4313\t- Test Loss: 0.1100\n",
      "- Epoch: 253\t- Train Loss: 0.4329\t- Test Loss: 0.1100\n",
      "- Epoch: 254\t- Train Loss: 0.4329\t- Test Loss: 0.1113\n",
      "- Epoch: 255\t- Train Loss: 0.4338\t- Test Loss: 0.1107\n",
      "- Epoch: 256\t- Train Loss: 0.4278\t- Test Loss: 0.1081\n",
      "- Epoch: 257\t- Train Loss: 0.4275\t- Test Loss: 0.1108\n",
      "- Epoch: 258\t- Train Loss: 0.4281\t- Test Loss: 0.1089\n",
      "- Epoch: 259\t- Train Loss: 0.4297\t- Test Loss: 0.1071\n",
      "- Epoch: 260\t- Train Loss: 0.4334\t- Test Loss: 0.1104\n",
      "- Epoch: 261\t- Train Loss: 0.4302\t- Test Loss: 0.1127\n",
      "- Epoch: 262\t- Train Loss: 0.4277\t- Test Loss: 0.1104\n",
      "- Epoch: 263\t- Train Loss: 0.4233\t- Test Loss: 0.1109\n",
      "- Epoch: 264\t- Train Loss: 0.4242\t- Test Loss: 0.1097\n",
      "- Epoch: 265\t- Train Loss: 0.4294\t- Test Loss: 0.1082\n",
      "- Epoch: 266\t- Train Loss: 0.4282\t- Test Loss: 0.1092\n",
      "- Epoch: 267\t- Train Loss: 0.4215\t- Test Loss: 0.1075\n",
      "- Epoch: 268\t- Train Loss: 0.4336\t- Test Loss: 0.1093\n",
      "- Epoch: 269\t- Train Loss: 0.4265\t- Test Loss: 0.1089\n",
      "- Epoch: 270\t- Train Loss: 0.4235\t- Test Loss: 0.1106\n",
      "- Epoch: 271\t- Train Loss: 0.4275\t- Test Loss: 0.1077\n",
      "- Epoch: 272\t- Train Loss: 0.4305\t- Test Loss: 0.1073\n",
      "- Epoch: 273\t- Train Loss: 0.4231\t- Test Loss: 0.1084\n",
      "- Epoch: 274\t- Train Loss: 0.4232\t- Test Loss: 0.1090\n",
      "- Epoch: 275\t- Train Loss: 0.4282\t- Test Loss: 0.1071\n",
      "- Epoch: 276\t- Train Loss: 0.4228\t- Test Loss: 0.1079\n",
      "- Epoch: 277\t- Train Loss: 0.4274\t- Test Loss: 0.1088\n",
      "- Epoch: 278\t- Train Loss: 0.4251\t- Test Loss: 0.1058\n",
      "- Epoch: 279\t- Train Loss: 0.4246\t- Test Loss: 0.1074\n",
      "- Epoch: 280\t- Train Loss: 0.4250\t- Test Loss: 0.1082\n",
      "- Epoch: 281\t- Train Loss: 0.4253\t- Test Loss: 0.1065\n",
      "- Epoch: 282\t- Train Loss: 0.4197\t- Test Loss: 0.1090\n",
      "- Epoch: 283\t- Train Loss: 0.4248\t- Test Loss: 0.1086\n",
      "- Epoch: 284\t- Train Loss: 0.4229\t- Test Loss: 0.1065\n",
      "- Epoch: 285\t- Train Loss: 0.4198\t- Test Loss: 0.1079\n",
      "- Epoch: 286\t- Train Loss: 0.4234\t- Test Loss: 0.1066\n",
      "- Epoch: 287\t- Train Loss: 0.4230\t- Test Loss: 0.1073\n",
      "- Epoch: 288\t- Train Loss: 0.4164\t- Test Loss: 0.1057\n",
      "- Epoch: 289\t- Train Loss: 0.4266\t- Test Loss: 0.1052\n",
      "- Epoch: 290\t- Train Loss: 0.4233\t- Test Loss: 0.1084\n",
      "- Epoch: 291\t- Train Loss: 0.4219\t- Test Loss: 0.1089\n",
      "- Epoch: 292\t- Train Loss: 0.4246\t- Test Loss: 0.1074\n",
      "- Epoch: 293\t- Train Loss: 0.4214\t- Test Loss: 0.1082\n",
      "- Epoch: 294\t- Train Loss: 0.4204\t- Test Loss: 0.1098\n",
      "- Epoch: 295\t- Train Loss: 0.4177\t- Test Loss: 0.1065\n",
      "- Epoch: 296\t- Train Loss: 0.4218\t- Test Loss: 0.1065\n",
      "- Epoch: 297\t- Train Loss: 0.4166\t- Test Loss: 0.1059\n",
      "- Epoch: 298\t- Train Loss: 0.4181\t- Test Loss: 0.1069\n",
      "- Epoch: 299\t- Train Loss: 0.4178\t- Test Loss: 0.1061\n",
      "- Epoch: 300\t- Train Loss: 0.4184\t- Test Loss: 0.1052\n",
      "- Epoch: 301\t- Train Loss: 0.4205\t- Test Loss: 0.1060\n",
      "- Epoch: 302\t- Train Loss: 0.4227\t- Test Loss: 0.1059\n",
      "- Epoch: 303\t- Train Loss: 0.4208\t- Test Loss: 0.1091\n",
      "- Epoch: 304\t- Train Loss: 0.4197\t- Test Loss: 0.1050\n",
      "- Epoch: 305\t- Train Loss: 0.4199\t- Test Loss: 0.1067\n",
      "- Epoch: 306\t- Train Loss: 0.4191\t- Test Loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch: 307\t- Train Loss: 0.4209\t- Test Loss: 0.1071\n",
      "- Epoch: 308\t- Train Loss: 0.4195\t- Test Loss: 0.1089\n",
      "- Epoch: 309\t- Train Loss: 0.4159\t- Test Loss: 0.1073\n",
      "- Epoch: 310\t- Train Loss: 0.4215\t- Test Loss: 0.1056\n",
      "- Epoch: 311\t- Train Loss: 0.4148\t- Test Loss: 0.1038\n",
      "- Epoch: 312\t- Train Loss: 0.4198\t- Test Loss: 0.1071\n",
      "- Epoch: 313\t- Train Loss: 0.4167\t- Test Loss: 0.1051\n",
      "- Epoch: 314\t- Train Loss: 0.4205\t- Test Loss: 0.1061\n",
      "- Epoch: 315\t- Train Loss: 0.4176\t- Test Loss: 0.1056\n",
      "- Epoch: 316\t- Train Loss: 0.4190\t- Test Loss: 0.1042\n",
      "- Epoch: 317\t- Train Loss: 0.4154\t- Test Loss: 0.1042\n",
      "- Epoch: 318\t- Train Loss: 0.4165\t- Test Loss: 0.1081\n",
      "- Epoch: 319\t- Train Loss: 0.4149\t- Test Loss: 0.1091\n",
      "- Epoch: 320\t- Train Loss: 0.4197\t- Test Loss: 0.1046\n",
      "- Epoch: 321\t- Train Loss: 0.4157\t- Test Loss: 0.1071\n",
      "- Epoch: 322\t- Train Loss: 0.4154\t- Test Loss: 0.1051\n",
      "- Epoch: 323\t- Train Loss: 0.4145\t- Test Loss: 0.1067\n",
      "- Epoch: 324\t- Train Loss: 0.4138\t- Test Loss: 0.1044\n",
      "- Epoch: 325\t- Train Loss: 0.4142\t- Test Loss: 0.1062\n",
      "- Epoch: 326\t- Train Loss: 0.4160\t- Test Loss: 0.1064\n",
      "- Epoch: 327\t- Train Loss: 0.4138\t- Test Loss: 0.1057\n",
      "- Epoch: 328\t- Train Loss: 0.4161\t- Test Loss: 0.1070\n",
      "- Epoch: 329\t- Train Loss: 0.4152\t- Test Loss: 0.1068\n",
      "- Epoch: 330\t- Train Loss: 0.4149\t- Test Loss: 0.1063\n",
      "- Epoch: 331\t- Train Loss: 0.4184\t- Test Loss: 0.1046\n",
      "- Epoch: 332\t- Train Loss: 0.4154\t- Test Loss: 0.1054\n",
      "- Epoch: 333\t- Train Loss: 0.4166\t- Test Loss: 0.1065\n",
      "- Epoch: 334\t- Train Loss: 0.4149\t- Test Loss: 0.1039\n",
      "- Epoch: 335\t- Train Loss: 0.4157\t- Test Loss: 0.1057\n",
      "- Epoch: 336\t- Train Loss: 0.4161\t- Test Loss: 0.1064\n",
      "- Epoch: 337\t- Train Loss: 0.4164\t- Test Loss: 0.1066\n",
      "- Epoch: 338\t- Train Loss: 0.4146\t- Test Loss: 0.1041\n",
      "- Epoch: 339\t- Train Loss: 0.4174\t- Test Loss: 0.1058\n",
      "- Epoch: 340\t- Train Loss: 0.4157\t- Test Loss: 0.1038\n",
      "- Epoch: 341\t- Train Loss: 0.4131\t- Test Loss: 0.1030\n",
      "- Epoch: 342\t- Train Loss: 0.4159\t- Test Loss: 0.1060\n",
      "- Epoch: 343\t- Train Loss: 0.4157\t- Test Loss: 0.1056\n",
      "- Epoch: 344\t- Train Loss: 0.4149\t- Test Loss: 0.1063\n",
      "- Epoch: 345\t- Train Loss: 0.4140\t- Test Loss: 0.1043\n",
      "- Epoch: 346\t- Train Loss: 0.4104\t- Test Loss: 0.1068\n",
      "- Epoch: 347\t- Train Loss: 0.4128\t- Test Loss: 0.1058\n",
      "- Epoch: 348\t- Train Loss: 0.4138\t- Test Loss: 0.1055\n",
      "- Epoch: 349\t- Train Loss: 0.4138\t- Test Loss: 0.1046\n",
      "- Epoch: 350\t- Train Loss: 0.4122\t- Test Loss: 0.1067\n",
      "- Epoch: 351\t- Train Loss: 0.4126\t- Test Loss: 0.1044\n",
      "- Epoch: 352\t- Train Loss: 0.4131\t- Test Loss: 0.1028\n",
      "- Epoch: 353\t- Train Loss: 0.4121\t- Test Loss: 0.1023\n",
      "- Epoch: 354\t- Train Loss: 0.4136\t- Test Loss: 0.1069\n",
      "- Epoch: 355\t- Train Loss: 0.4152\t- Test Loss: 0.1076\n",
      "- Epoch: 356\t- Train Loss: 0.4122\t- Test Loss: 0.1051\n",
      "- Epoch: 357\t- Train Loss: 0.4111\t- Test Loss: 0.1060\n",
      "- Epoch: 358\t- Train Loss: 0.4129\t- Test Loss: 0.1058\n",
      "- Epoch: 359\t- Train Loss: 0.4142\t- Test Loss: 0.1033\n",
      "- Epoch: 360\t- Train Loss: 0.4117\t- Test Loss: 0.1039\n",
      "- Epoch: 361\t- Train Loss: 0.4104\t- Test Loss: 0.1038\n",
      "- Epoch: 362\t- Train Loss: 0.4180\t- Test Loss: 0.1056\n",
      "- Epoch: 363\t- Train Loss: 0.4069\t- Test Loss: 0.1072\n",
      "- Epoch: 364\t- Train Loss: 0.4133\t- Test Loss: 0.1030\n",
      "- Epoch: 365\t- Train Loss: 0.4117\t- Test Loss: 0.1058\n",
      "- Epoch: 366\t- Train Loss: 0.4105\t- Test Loss: 0.1076\n",
      "- Epoch: 367\t- Train Loss: 0.4134\t- Test Loss: 0.1048\n",
      "- Epoch: 368\t- Train Loss: 0.4106\t- Test Loss: 0.1045\n",
      "- Epoch: 369\t- Train Loss: 0.4109\t- Test Loss: 0.1029\n",
      "- Epoch: 370\t- Train Loss: 0.4098\t- Test Loss: 0.1044\n",
      "- Epoch: 371\t- Train Loss: 0.4135\t- Test Loss: 0.1040\n",
      "- Epoch: 372\t- Train Loss: 0.4120\t- Test Loss: 0.1053\n",
      "- Epoch: 373\t- Train Loss: 0.4141\t- Test Loss: 0.1049\n",
      "- Epoch: 374\t- Train Loss: 0.4108\t- Test Loss: 0.1057\n",
      "- Epoch: 375\t- Train Loss: 0.4104\t- Test Loss: 0.1047\n",
      "- Epoch: 376\t- Train Loss: 0.4082\t- Test Loss: 0.1046\n",
      "- Epoch: 377\t- Train Loss: 0.4098\t- Test Loss: 0.1027\n",
      "- Epoch: 378\t- Train Loss: 0.4080\t- Test Loss: 0.1035\n",
      "- Epoch: 379\t- Train Loss: 0.4127\t- Test Loss: 0.1031\n",
      "- Epoch: 380\t- Train Loss: 0.4092\t- Test Loss: 0.1033\n",
      "- Epoch: 381\t- Train Loss: 0.4130\t- Test Loss: 0.1059\n",
      "- Epoch: 382\t- Train Loss: 0.4135\t- Test Loss: 0.1030\n",
      "- Epoch: 383\t- Train Loss: 0.4088\t- Test Loss: 0.1029\n",
      "- Epoch: 384\t- Train Loss: 0.4127\t- Test Loss: 0.1036\n",
      "- Epoch: 385\t- Train Loss: 0.4083\t- Test Loss: 0.1045\n",
      "- Epoch: 386\t- Train Loss: 0.4114\t- Test Loss: 0.1048\n",
      "- Epoch: 387\t- Train Loss: 0.4107\t- Test Loss: 0.1037\n",
      "- Epoch: 388\t- Train Loss: 0.4121\t- Test Loss: 0.1024\n",
      "- Epoch: 389\t- Train Loss: 0.4082\t- Test Loss: 0.1034\n",
      "- Epoch: 390\t- Train Loss: 0.4108\t- Test Loss: 0.1018\n",
      "- Epoch: 391\t- Train Loss: 0.4092\t- Test Loss: 0.1043\n",
      "- Epoch: 392\t- Train Loss: 0.4097\t- Test Loss: 0.1028\n",
      "- Epoch: 393\t- Train Loss: 0.4043\t- Test Loss: 0.1049\n",
      "- Epoch: 394\t- Train Loss: 0.4133\t- Test Loss: 0.1020\n",
      "- Epoch: 395\t- Train Loss: 0.4109\t- Test Loss: 0.1038\n",
      "- Epoch: 396\t- Train Loss: 0.4103\t- Test Loss: 0.1041\n",
      "- Epoch: 397\t- Train Loss: 0.4130\t- Test Loss: 0.1027\n",
      "- Epoch: 398\t- Train Loss: 0.4093\t- Test Loss: 0.1053\n",
      "- Epoch: 399\t- Train Loss: 0.4098\t- Test Loss: 0.1028\n",
      "- Epoch: 400\t- Train Loss: 0.4079\t- Test Loss: 0.1045\n",
      "- Epoch: 401\t- Train Loss: 0.4065\t- Test Loss: 0.1047\n",
      "- Epoch: 402\t- Train Loss: 0.4091\t- Test Loss: 0.1055\n",
      "- Epoch: 403\t- Train Loss: 0.4093\t- Test Loss: 0.1054\n",
      "- Epoch: 404\t- Train Loss: 0.4101\t- Test Loss: 0.1055\n",
      "- Epoch: 405\t- Train Loss: 0.4016\t- Test Loss: 0.1038\n",
      "- Epoch: 406\t- Train Loss: 0.4128\t- Test Loss: 0.1021\n",
      "- Epoch: 407\t- Train Loss: 0.4051\t- Test Loss: 0.1041\n",
      "- Epoch: 408\t- Train Loss: 0.4115\t- Test Loss: 0.1047\n",
      "- Epoch: 409\t- Train Loss: 0.4060\t- Test Loss: 0.1029\n",
      "- Epoch: 410\t- Train Loss: 0.4058\t- Test Loss: 0.1049\n",
      "- Epoch: 411\t- Train Loss: 0.4107\t- Test Loss: 0.1033\n",
      "- Epoch: 412\t- Train Loss: 0.4074\t- Test Loss: 0.1030\n",
      "- Epoch: 413\t- Train Loss: 0.4014\t- Test Loss: 0.1033\n",
      "- Epoch: 414\t- Train Loss: 0.4077\t- Test Loss: 0.1033\n",
      "- Epoch: 415\t- Train Loss: 0.4061\t- Test Loss: 0.1038\n",
      "- Epoch: 416\t- Train Loss: 0.4109\t- Test Loss: 0.1033\n",
      "- Epoch: 417\t- Train Loss: 0.4087\t- Test Loss: 0.1048\n",
      "- Epoch: 418\t- Train Loss: 0.4067\t- Test Loss: 0.1016\n",
      "- Epoch: 419\t- Train Loss: 0.4083\t- Test Loss: 0.1059\n",
      "- Epoch: 420\t- Train Loss: 0.4123\t- Test Loss: 0.1049\n",
      "- Epoch: 421\t- Train Loss: 0.4067\t- Test Loss: 0.1004\n",
      "- Epoch: 422\t- Train Loss: 0.4062\t- Test Loss: 0.1028\n",
      "- Epoch: 423\t- Train Loss: 0.4053\t- Test Loss: 0.1056\n",
      "- Epoch: 424\t- Train Loss: 0.4020\t- Test Loss: 0.1033\n",
      "- Epoch: 425\t- Train Loss: 0.4084\t- Test Loss: 0.1024\n",
      "- Epoch: 426\t- Train Loss: 0.4078\t- Test Loss: 0.1011\n",
      "- Epoch: 427\t- Train Loss: 0.4042\t- Test Loss: 0.1046\n",
      "- Epoch: 428\t- Train Loss: 0.4049\t- Test Loss: 0.1051\n",
      "- Epoch: 429\t- Train Loss: 0.4055\t- Test Loss: 0.1025\n",
      "- Epoch: 430\t- Train Loss: 0.4098\t- Test Loss: 0.1046\n",
      "- Epoch: 431\t- Train Loss: 0.4107\t- Test Loss: 0.1056\n",
      "- Epoch: 432\t- Train Loss: 0.4020\t- Test Loss: 0.1038\n",
      "- Epoch: 433\t- Train Loss: 0.4056\t- Test Loss: 0.1042\n",
      "- Epoch: 434\t- Train Loss: 0.4084\t- Test Loss: 0.1043\n",
      "- Epoch: 435\t- Train Loss: 0.4065\t- Test Loss: 0.1018\n",
      "- Epoch: 436\t- Train Loss: 0.4103\t- Test Loss: 0.1047\n",
      "- Epoch: 437\t- Train Loss: 0.4081\t- Test Loss: 0.1016\n",
      "- Epoch: 438\t- Train Loss: 0.4045\t- Test Loss: 0.1025\n",
      "- Epoch: 439\t- Train Loss: 0.4060\t- Test Loss: 0.1044\n",
      "- Epoch: 440\t- Train Loss: 0.4095\t- Test Loss: 0.1038\n",
      "- Epoch: 441\t- Train Loss: 0.4048\t- Test Loss: 0.1037\n",
      "- Epoch: 442\t- Train Loss: 0.4050\t- Test Loss: 0.1030\n",
      "- Epoch: 443\t- Train Loss: 0.4021\t- Test Loss: 0.1031\n",
      "- Epoch: 444\t- Train Loss: 0.4057\t- Test Loss: 0.1024\n",
      "- Epoch: 445\t- Train Loss: 0.4037\t- Test Loss: 0.1038\n",
      "- Epoch: 446\t- Train Loss: 0.4093\t- Test Loss: 0.1034\n",
      "- Epoch: 447\t- Train Loss: 0.4067\t- Test Loss: 0.1020\n",
      "- Epoch: 448\t- Train Loss: 0.4048\t- Test Loss: 0.1030\n",
      "- Epoch: 449\t- Train Loss: 0.4092\t- Test Loss: 0.1024\n",
      "- Epoch: 450\t- Train Loss: 0.4087\t- Test Loss: 0.1042\n",
      "- Epoch: 451\t- Train Loss: 0.4078\t- Test Loss: 0.1033\n",
      "- Epoch: 452\t- Train Loss: 0.4095\t- Test Loss: 0.1009\n",
      "- Epoch: 453\t- Train Loss: 0.4017\t- Test Loss: 0.1028\n",
      "- Epoch: 454\t- Train Loss: 0.4082\t- Test Loss: 0.1026\n",
      "- Epoch: 455\t- Train Loss: 0.4058\t- Test Loss: 0.1050\n",
      "- Epoch: 456\t- Train Loss: 0.4085\t- Test Loss: 0.1041\n",
      "- Epoch: 457\t- Train Loss: 0.4086\t- Test Loss: 0.1022\n",
      "- Epoch: 458\t- Train Loss: 0.4022\t- Test Loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch: 459\t- Train Loss: 0.4039\t- Test Loss: 0.1033\n",
      "- Epoch: 460\t- Train Loss: 0.4013\t- Test Loss: 0.1033\n",
      "- Epoch: 461\t- Train Loss: 0.4094\t- Test Loss: 0.1034\n",
      "- Epoch: 462\t- Train Loss: 0.4099\t- Test Loss: 0.1071\n",
      "- Epoch: 463\t- Train Loss: 0.4048\t- Test Loss: 0.1044\n",
      "- Epoch: 464\t- Train Loss: 0.4073\t- Test Loss: 0.1036\n",
      "- Epoch: 465\t- Train Loss: 0.4098\t- Test Loss: 0.1024\n",
      "- Epoch: 466\t- Train Loss: 0.4052\t- Test Loss: 0.1033\n",
      "- Epoch: 467\t- Train Loss: 0.4026\t- Test Loss: 0.1040\n",
      "- Epoch: 468\t- Train Loss: 0.4051\t- Test Loss: 0.1047\n",
      "- Epoch: 469\t- Train Loss: 0.4023\t- Test Loss: 0.1024\n",
      "- Epoch: 470\t- Train Loss: 0.4060\t- Test Loss: 0.1046\n",
      "- Epoch: 471\t- Train Loss: 0.4059\t- Test Loss: 0.1021\n",
      "- Epoch: 472\t- Train Loss: 0.4026\t- Test Loss: 0.1040\n",
      "- Epoch: 473\t- Train Loss: 0.4034\t- Test Loss: 0.1040\n",
      "- Epoch: 474\t- Train Loss: 0.4061\t- Test Loss: 0.1031\n",
      "- Epoch: 475\t- Train Loss: 0.4049\t- Test Loss: 0.1042\n",
      "- Epoch: 476\t- Train Loss: 0.4110\t- Test Loss: 0.1032\n",
      "- Epoch: 477\t- Train Loss: 0.4059\t- Test Loss: 0.1030\n",
      "- Epoch: 478\t- Train Loss: 0.4064\t- Test Loss: 0.1009\n",
      "- Epoch: 479\t- Train Loss: 0.4044\t- Test Loss: 0.1029\n",
      "- Epoch: 480\t- Train Loss: 0.4115\t- Test Loss: 0.1027\n",
      "- Epoch: 481\t- Train Loss: 0.4040\t- Test Loss: 0.1048\n",
      "- Epoch: 482\t- Train Loss: 0.4086\t- Test Loss: 0.1043\n",
      "- Epoch: 483\t- Train Loss: 0.4034\t- Test Loss: 0.1035\n",
      "- Epoch: 484\t- Train Loss: 0.4060\t- Test Loss: 0.1036\n",
      "- Epoch: 485\t- Train Loss: 0.4054\t- Test Loss: 0.1039\n",
      "- Epoch: 486\t- Train Loss: 0.4046\t- Test Loss: 0.1036\n",
      "- Epoch: 487\t- Train Loss: 0.4091\t- Test Loss: 0.1018\n",
      "- Epoch: 488\t- Train Loss: 0.4084\t- Test Loss: 0.1028\n",
      "- Epoch: 489\t- Train Loss: 0.4087\t- Test Loss: 0.1036\n",
      "- Epoch: 490\t- Train Loss: 0.4058\t- Test Loss: 0.1049\n",
      "- Epoch: 491\t- Train Loss: 0.4028\t- Test Loss: 0.1049\n",
      "- Epoch: 492\t- Train Loss: 0.4095\t- Test Loss: 0.1014\n",
      "- Epoch: 493\t- Train Loss: 0.4053\t- Test Loss: 0.1021\n",
      "- Epoch: 494\t- Train Loss: 0.4058\t- Test Loss: 0.1049\n",
      "- Epoch: 495\t- Train Loss: 0.4055\t- Test Loss: 0.1033\n",
      "- Epoch: 496\t- Train Loss: 0.4033\t- Test Loss: 0.1030\n",
      "- Epoch: 497\t- Train Loss: 0.4032\t- Test Loss: 0.1024\n",
      "- Epoch: 498\t- Train Loss: 0.4051\t- Test Loss: 0.1033\n",
      "- Epoch: 499\t- Train Loss: 0.4042\t- Test Loss: 0.1026\n",
      "- Epoch: 500\t- Train Loss: 0.4083\t- Test Loss: 0.1058\n",
      "- Epoch: 501\t- Train Loss: 0.4030\t- Test Loss: 0.1003\n",
      "- Epoch: 502\t- Train Loss: 0.4011\t- Test Loss: 0.1031\n",
      "- Epoch: 503\t- Train Loss: 0.4070\t- Test Loss: 0.1031\n",
      "- Epoch: 504\t- Train Loss: 0.4054\t- Test Loss: 0.1048\n",
      "- Epoch: 505\t- Train Loss: 0.4030\t- Test Loss: 0.1007\n",
      "- Epoch: 506\t- Train Loss: 0.4074\t- Test Loss: 0.1032\n",
      "- Epoch: 507\t- Train Loss: 0.4038\t- Test Loss: 0.1034\n",
      "- Epoch: 508\t- Train Loss: 0.4052\t- Test Loss: 0.1010\n",
      "- Epoch: 509\t- Train Loss: 0.4074\t- Test Loss: 0.1026\n",
      "- Epoch: 510\t- Train Loss: 0.4072\t- Test Loss: 0.1054\n",
      "- Epoch: 511\t- Train Loss: 0.4073\t- Test Loss: 0.1036\n",
      "- Epoch: 512\t- Train Loss: 0.4062\t- Test Loss: 0.1044\n",
      "- Epoch: 513\t- Train Loss: 0.4031\t- Test Loss: 0.1018\n",
      "- Epoch: 514\t- Train Loss: 0.4054\t- Test Loss: 0.1024\n",
      "- Epoch: 515\t- Train Loss: 0.4081\t- Test Loss: 0.1042\n",
      "- Epoch: 516\t- Train Loss: 0.4030\t- Test Loss: 0.1029\n",
      "- Epoch: 517\t- Train Loss: 0.4056\t- Test Loss: 0.1024\n",
      "- Epoch: 518\t- Train Loss: 0.4090\t- Test Loss: 0.1043\n",
      "- Epoch: 519\t- Train Loss: 0.4040\t- Test Loss: 0.1018\n",
      "- Epoch: 520\t- Train Loss: 0.4066\t- Test Loss: 0.1032\n",
      "- Epoch: 521\t- Train Loss: 0.4049\t- Test Loss: 0.1049\n",
      "- Epoch: 522\t- Train Loss: 0.4056\t- Test Loss: 0.1060\n",
      "- Epoch: 523\t- Train Loss: 0.4100\t- Test Loss: 0.1027\n",
      "- Epoch: 524\t- Train Loss: 0.4036\t- Test Loss: 0.1042\n",
      "- Epoch: 525\t- Train Loss: 0.4065\t- Test Loss: 0.1026\n",
      "- Epoch: 526\t- Train Loss: 0.4044\t- Test Loss: 0.1031\n",
      "- Epoch: 527\t- Train Loss: 0.4050\t- Test Loss: 0.1033\n",
      "- Epoch: 528\t- Train Loss: 0.4016\t- Test Loss: 0.1045\n",
      "- Epoch: 529\t- Train Loss: 0.4059\t- Test Loss: 0.1034\n",
      "- Epoch: 530\t- Train Loss: 0.4027\t- Test Loss: 0.1024\n",
      "- Epoch: 531\t- Train Loss: 0.4074\t- Test Loss: 0.1020\n",
      "- Epoch: 532\t- Train Loss: 0.4063\t- Test Loss: 0.1033\n",
      "- Epoch: 533\t- Train Loss: 0.4057\t- Test Loss: 0.1029\n",
      "- Epoch: 534\t- Train Loss: 0.4043\t- Test Loss: 0.1024\n",
      "- Epoch: 535\t- Train Loss: 0.4014\t- Test Loss: 0.1034\n",
      "- Epoch: 536\t- Train Loss: 0.4044\t- Test Loss: 0.1036\n",
      "- Epoch: 537\t- Train Loss: 0.4080\t- Test Loss: 0.1029\n",
      "- Epoch: 538\t- Train Loss: 0.4041\t- Test Loss: 0.1016\n",
      "- Epoch: 539\t- Train Loss: 0.4065\t- Test Loss: 0.0999\n",
      "- Epoch: 540\t- Train Loss: 0.4001\t- Test Loss: 0.1015\n",
      "- Epoch: 541\t- Train Loss: 0.4048\t- Test Loss: 0.1026\n",
      "- Epoch: 542\t- Train Loss: 0.4065\t- Test Loss: 0.1007\n",
      "- Epoch: 543\t- Train Loss: 0.4036\t- Test Loss: 0.1043\n",
      "- Epoch: 544\t- Train Loss: 0.4031\t- Test Loss: 0.1029\n",
      "- Epoch: 545\t- Train Loss: 0.4067\t- Test Loss: 0.1041\n",
      "- Epoch: 546\t- Train Loss: 0.4062\t- Test Loss: 0.1030\n",
      "- Epoch: 547\t- Train Loss: 0.4058\t- Test Loss: 0.1025\n",
      "- Epoch: 548\t- Train Loss: 0.4069\t- Test Loss: 0.1034\n",
      "- Epoch: 549\t- Train Loss: 0.4024\t- Test Loss: 0.1004\n",
      "- Epoch: 550\t- Train Loss: 0.4008\t- Test Loss: 0.1017\n",
      "- Epoch: 551\t- Train Loss: 0.4054\t- Test Loss: 0.1032\n",
      "- Epoch: 552\t- Train Loss: 0.4035\t- Test Loss: 0.1014\n",
      "- Epoch: 553\t- Train Loss: 0.4052\t- Test Loss: 0.1014\n",
      "- Epoch: 554\t- Train Loss: 0.4021\t- Test Loss: 0.1006\n",
      "- Epoch: 555\t- Train Loss: 0.4006\t- Test Loss: 0.1032\n",
      "- Epoch: 556\t- Train Loss: 0.4115\t- Test Loss: 0.1016\n",
      "- Epoch: 557\t- Train Loss: 0.4056\t- Test Loss: 0.1043\n",
      "- Epoch: 558\t- Train Loss: 0.4066\t- Test Loss: 0.1036\n",
      "- Epoch: 559\t- Train Loss: 0.4049\t- Test Loss: 0.1028\n",
      "- Epoch: 560\t- Train Loss: 0.4040\t- Test Loss: 0.0994\n",
      "- Epoch: 561\t- Train Loss: 0.4046\t- Test Loss: 0.1012\n",
      "- Epoch: 562\t- Train Loss: 0.4110\t- Test Loss: 0.1031\n",
      "- Epoch: 563\t- Train Loss: 0.4083\t- Test Loss: 0.1030\n",
      "- Epoch: 564\t- Train Loss: 0.4044\t- Test Loss: 0.1003\n",
      "- Epoch: 565\t- Train Loss: 0.4011\t- Test Loss: 0.1044\n",
      "- Epoch: 566\t- Train Loss: 0.4040\t- Test Loss: 0.1023\n",
      "- Epoch: 567\t- Train Loss: 0.4034\t- Test Loss: 0.1027\n",
      "- Epoch: 568\t- Train Loss: 0.4101\t- Test Loss: 0.1020\n",
      "- Epoch: 569\t- Train Loss: 0.4092\t- Test Loss: 0.1035\n",
      "- Epoch: 570\t- Train Loss: 0.4025\t- Test Loss: 0.1023\n",
      "- Epoch: 571\t- Train Loss: 0.4014\t- Test Loss: 0.1018\n",
      "- Epoch: 572\t- Train Loss: 0.4024\t- Test Loss: 0.1022\n",
      "- Epoch: 573\t- Train Loss: 0.4004\t- Test Loss: 0.1030\n",
      "- Epoch: 574\t- Train Loss: 0.4040\t- Test Loss: 0.1033\n",
      "- Epoch: 575\t- Train Loss: 0.4028\t- Test Loss: 0.1028\n",
      "- Epoch: 576\t- Train Loss: 0.3996\t- Test Loss: 0.1027\n",
      "- Epoch: 577\t- Train Loss: 0.4013\t- Test Loss: 0.1024\n",
      "- Epoch: 578\t- Train Loss: 0.4061\t- Test Loss: 0.1043\n",
      "- Epoch: 579\t- Train Loss: 0.4030\t- Test Loss: 0.1045\n",
      "- Epoch: 580\t- Train Loss: 0.4015\t- Test Loss: 0.1045\n",
      "- Epoch: 581\t- Train Loss: 0.4036\t- Test Loss: 0.1023\n",
      "- Epoch: 582\t- Train Loss: 0.4080\t- Test Loss: 0.1040\n",
      "- Epoch: 583\t- Train Loss: 0.4054\t- Test Loss: 0.1040\n",
      "- Epoch: 584\t- Train Loss: 0.4062\t- Test Loss: 0.1021\n",
      "- Epoch: 585\t- Train Loss: 0.4022\t- Test Loss: 0.1035\n",
      "- Epoch: 586\t- Train Loss: 0.4075\t- Test Loss: 0.1039\n",
      "- Epoch: 587\t- Train Loss: 0.4066\t- Test Loss: 0.1016\n",
      "- Epoch: 588\t- Train Loss: 0.4042\t- Test Loss: 0.1018\n",
      "- Epoch: 589\t- Train Loss: 0.4007\t- Test Loss: 0.1031\n",
      "- Epoch: 590\t- Train Loss: 0.4048\t- Test Loss: 0.1033\n",
      "- Epoch: 591\t- Train Loss: 0.4044\t- Test Loss: 0.1017\n",
      "- Epoch: 592\t- Train Loss: 0.4014\t- Test Loss: 0.1023\n",
      "- Epoch: 593\t- Train Loss: 0.4023\t- Test Loss: 0.1040\n",
      "- Epoch: 594\t- Train Loss: 0.4004\t- Test Loss: 0.1023\n",
      "- Epoch: 595\t- Train Loss: 0.4003\t- Test Loss: 0.1033\n",
      "- Epoch: 596\t- Train Loss: 0.4032\t- Test Loss: 0.1038\n",
      "- Epoch: 597\t- Train Loss: 0.4038\t- Test Loss: 0.1013\n",
      "- Epoch: 598\t- Train Loss: 0.4075\t- Test Loss: 0.1020\n",
      "- Epoch: 599\t- Train Loss: 0.4046\t- Test Loss: 0.1029\n",
      "- Epoch: 600\t- Train Loss: 0.4042\t- Test Loss: 0.1003\n",
      "- Epoch: 601\t- Train Loss: 0.4049\t- Test Loss: 0.1037\n",
      "- Epoch: 602\t- Train Loss: 0.4062\t- Test Loss: 0.1029\n",
      "- Epoch: 603\t- Train Loss: 0.4052\t- Test Loss: 0.1022\n",
      "- Epoch: 604\t- Train Loss: 0.3999\t- Test Loss: 0.1030\n",
      "- Epoch: 605\t- Train Loss: 0.4056\t- Test Loss: 0.1035\n",
      "- Epoch: 606\t- Train Loss: 0.4040\t- Test Loss: 0.1038\n",
      "- Epoch: 607\t- Train Loss: 0.4024\t- Test Loss: 0.1012\n",
      "- Epoch: 608\t- Train Loss: 0.4040\t- Test Loss: 0.1037\n",
      "- Epoch: 609\t- Train Loss: 0.4005\t- Test Loss: 0.1027\n",
      "- Epoch: 610\t- Train Loss: 0.4014\t- Test Loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Epoch: 611\t- Train Loss: 0.4060\t- Test Loss: 0.1048\n",
      "- Epoch: 612\t- Train Loss: 0.4076\t- Test Loss: 0.1033\n",
      "- Epoch: 613\t- Train Loss: 0.4010\t- Test Loss: 0.1032\n",
      "- Epoch: 614\t- Train Loss: 0.4061\t- Test Loss: 0.1017\n",
      "- Epoch: 615\t- Train Loss: 0.4000\t- Test Loss: 0.1028\n",
      "- Epoch: 616\t- Train Loss: 0.4023\t- Test Loss: 0.1018\n",
      "- Epoch: 617\t- Train Loss: 0.4071\t- Test Loss: 0.1046\n",
      "- Epoch: 618\t- Train Loss: 0.4089\t- Test Loss: 0.1014\n",
      "- Epoch: 619\t- Train Loss: 0.4047\t- Test Loss: 0.1011\n",
      "- Epoch: 620\t- Train Loss: 0.4033\t- Test Loss: 0.1022\n",
      "- Epoch: 621\t- Train Loss: 0.4040\t- Test Loss: 0.1028\n",
      "- Epoch: 622\t- Train Loss: 0.4035\t- Test Loss: 0.1038\n",
      "- Epoch: 623\t- Train Loss: 0.4072\t- Test Loss: 0.1024\n",
      "- Epoch: 624\t- Train Loss: 0.4046\t- Test Loss: 0.1039\n",
      "- Epoch: 625\t- Train Loss: 0.4022\t- Test Loss: 0.1028\n",
      "- Epoch: 626\t- Train Loss: 0.4030\t- Test Loss: 0.1014\n",
      "- Epoch: 627\t- Train Loss: 0.4059\t- Test Loss: 0.1038\n",
      "- Epoch: 628\t- Train Loss: 0.4059\t- Test Loss: 0.1026\n",
      "- Epoch: 629\t- Train Loss: 0.4004\t- Test Loss: 0.1028\n",
      "- Epoch: 630\t- Train Loss: 0.4062\t- Test Loss: 0.1008\n",
      "- Epoch: 631\t- Train Loss: 0.4050\t- Test Loss: 0.1025\n",
      "- Epoch: 632\t- Train Loss: 0.4013\t- Test Loss: 0.1015\n",
      "- Epoch: 633\t- Train Loss: 0.4049\t- Test Loss: 0.1034\n",
      "- Epoch: 634\t- Train Loss: 0.4088\t- Test Loss: 0.1034\n",
      "- Epoch: 635\t- Train Loss: 0.4037\t- Test Loss: 0.1023\n",
      "- Epoch: 636\t- Train Loss: 0.4020\t- Test Loss: 0.1038\n",
      "- Epoch: 637\t- Train Loss: 0.4050\t- Test Loss: 0.1035\n",
      "- Epoch: 638\t- Train Loss: 0.4042\t- Test Loss: 0.1046\n",
      "- Epoch: 639\t- Train Loss: 0.4034\t- Test Loss: 0.1047\n",
      "- Epoch: 640\t- Train Loss: 0.4012\t- Test Loss: 0.1015\n",
      "- Epoch: 641\t- Train Loss: 0.4058\t- Test Loss: 0.1012\n",
      "- Epoch: 642\t- Train Loss: 0.4026\t- Test Loss: 0.1035\n",
      "- Epoch: 643\t- Train Loss: 0.4039\t- Test Loss: 0.1028\n",
      "- Epoch: 644\t- Train Loss: 0.4021\t- Test Loss: 0.1032\n",
      "- Epoch: 645\t- Train Loss: 0.4034\t- Test Loss: 0.1018\n",
      "- Epoch: 646\t- Train Loss: 0.3993\t- Test Loss: 0.1020\n",
      "- Epoch: 647\t- Train Loss: 0.4009\t- Test Loss: 0.1042\n",
      "- Epoch: 648\t- Train Loss: 0.4027\t- Test Loss: 0.1023\n",
      "- Epoch: 649\t- Train Loss: 0.4042\t- Test Loss: 0.1034\n",
      "- Epoch: 650\t- Train Loss: 0.4056\t- Test Loss: 0.1025\n",
      "- Epoch: 651\t- Train Loss: 0.4038\t- Test Loss: 0.1043\n",
      "- Epoch: 652\t- Train Loss: 0.4038\t- Test Loss: 0.1019\n",
      "- Epoch: 653\t- Train Loss: 0.4074\t- Test Loss: 0.1021\n",
      "- Epoch: 654\t- Train Loss: 0.4049\t- Test Loss: 0.1020\n",
      "- Epoch: 655\t- Train Loss: 0.4010\t- Test Loss: 0.1035\n",
      "- Epoch: 656\t- Train Loss: 0.3999\t- Test Loss: 0.1029\n",
      "- Epoch: 657\t- Train Loss: 0.4063\t- Test Loss: 0.1000\n",
      "- Epoch: 658\t- Train Loss: 0.4029\t- Test Loss: 0.1020\n",
      "- Epoch: 659\t- Train Loss: 0.4057\t- Test Loss: 0.1031\n",
      "- Epoch: 660\t- Train Loss: 0.4024\t- Test Loss: 0.0997\n",
      "Early stopping\n",
      "[Tets]\n",
      "Accuracy : 0.90\n",
      "Micro F1 Score : 0.90\n",
      "Macro F1 Score : 0.86\n"
     ]
    }
   ],
   "source": [
    "args.batch_size = 512\n",
    "args.optim = 'Adam'\n",
    "args.step_size = 10\n",
    "args.gamma = 0.9\n",
    "args.dropout = 0.2\n",
    "args.lr = 0.0001\n",
    "args.epoch = 3000\n",
    "args.patience = 100\n",
    "args.n_features = 27\n",
    "conv_dim = 128\n",
    "args.conv_dim1 = conv_dim\n",
    "args.conv_dim2 = conv_dim\n",
    "args.conv_dim3 = conv_dim\n",
    "args.concat_dim = 128\n",
    "args.pred_dim1 = 128\n",
    "args.pred_dim2 = 64\n",
    "args.pred_dim3 = 32\n",
    "args.out_dim = len(classes)\n",
    "args.classes = [k for k in classes.keys()]\n",
    "\n",
    "model = Net(args)\n",
    "model = model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_X, batch_size=args.batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_X, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "dict_result = dict()\n",
    "args.exp_name = f'Exp'\n",
    "result = vars(experiment(model, train_loader, test_loader, device, args, prints=True))\n",
    "dict_result[args.exp_name] = copy.deepcopy(result)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "result_df = pd.DataFrame(dict_result).transpose()\n",
    "result_df.to_csv(f'./result_head.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.90\n",
      "Micro F1 Score : 0.90\n",
      "Macro F1 Score : 0.86\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm, acc, micf1, macf1 = plot_result(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
